{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Pandas to make datacleaning easier, deal with missing values and prepare the data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/spsyg6_d2nd8f42x3pkg_vv00000gn/T/ipykernel_86976/210375984.py:36: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  electricity_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/ElectricCost.csv')\n",
      "/var/folders/5y/spsyg6_d2nd8f42x3pkg_vv00000gn/T/ipykernel_86976/210375984.py:38: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cookinggas_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/cookinggas.csv')\n"
     ]
    }
   ],
   "source": [
    "#Reading all datasets in 'Housing Prices' tab\n",
    "all_homes = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/All_homes.csv')\n",
    "one_bedroom = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/1_bedroom_homes.csv')\n",
    "two_bedroom = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/2_bedroom_homes.csv')\n",
    "three_bedroom = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/3_bedroom_homes.csv')\n",
    "four_bedroom = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/4_bedroom_homes.csv')\n",
    "five_bedroom = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/5_bedroom_homes.csv')\n",
    "all_homes_forecast = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/forecasted_home_values.csv')\n",
    "all_homes_observed_rent = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/All_homes_observed_rent.csv')\n",
    "\n",
    "#Reading all datasets in 'Education' tab\n",
    "high_school_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/high_school.csv')\n",
    "library_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/library.csv') \n",
    "\n",
    "#Reading all datasets for Transportation\n",
    "subway_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/subway_stations.csv')\n",
    "borough_traffic_averages = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/traffic_volume.csv') \n",
    "demo_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/nyc_census_tracts.csv')\n",
    "\n",
    "#Reading all datasets under 'Health and Environment' tab\n",
    "parks_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/parks.csv')\n",
    "\n",
    "#Reading the dataset for Hospitals\n",
    "hospitals_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/Hospitals.csv')\n",
    "\n",
    "#Reading all datasets in 'Entertainment and Recreation tab'\n",
    "restaurants_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/restaurants.csv')\n",
    "swimmingpool_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/swimmingpool.csv')\n",
    "museum_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/museums.csv')\n",
    "markets_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/markets.csv')\n",
    "theatres_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/theatres.csv')\n",
    "beaches_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/beaches.csv')\n",
    "athleticfacilities_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/athletics.csv')\n",
    "\n",
    "#Reading all datasets in 'Utilities' tab\n",
    "electricity_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/ElectricCost.csv')\n",
    "firehouselocations_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/firehouselocations.csv')\n",
    "cookinggas_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/cookinggas.csv')\n",
    "wifi_hotspot_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/Wifihotspot.csv')\n",
    "grocery_stores = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/grocery_stores.csv')\n",
    "\n",
    "#Reading all datasets in 'Upcoming Projects' tab\n",
    "projects_under_constr_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/projects_under_constr.csv')\n",
    "\n",
    "#Reading all datasets in 'Location Data' tab\n",
    "nyc_zip_borough_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/nyc_zip-borough.csv')\n",
    "borough_master_df = pd.read_csv('/Users/tanvidineshnandu/Desktop/md_data_folder/borough_master_db.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to SQL - postgress (db name : 'nyc_projectmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Database connection URL\n",
    "DATABASE_URL = \"postgresql://postgres:123@localhost:5432/nyc_projectmd\"\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics' datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CensusTract County Borough  TotalPop   Men  Women  Hispanic  White  Black  \\\n",
      "0  36005000100  Bronx   Bronx      7703  7133    570      29.9    6.1   60.9   \n",
      "1  36005000200  Bronx   Bronx      5403  2659   2744      75.8    2.3   16.0   \n",
      "2  36005000400  Bronx   Bronx      5915  2896   3019      62.7    3.6   30.7   \n",
      "3  36005001600  Bronx   Bronx      5879  2558   3321      65.1    1.6   32.4   \n",
      "4  36005001900  Bronx   Bronx      2591  1206   1385      55.4    9.0   29.0   \n",
      "\n",
      "   Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
      "0     0.2  ...   NaN          NaN         NaN          NaN         0   \n",
      "1     0.0  ...   2.9          0.0         0.0         43.0      2308   \n",
      "2     0.0  ...   1.4          0.5         2.1         45.0      2675   \n",
      "3     0.0  ...   8.6          1.6         1.7         38.8      2120   \n",
      "4     0.0  ...   3.0          2.4         6.2         45.4      1083   \n",
      "\n",
      "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
      "0          NaN         NaN           NaN         NaN           NaN  \n",
      "1         80.8        16.2           2.9         0.0           7.7  \n",
      "2         71.7        25.3           2.5         0.6           9.5  \n",
      "3         75.0        21.3           3.8         0.0           8.7  \n",
      "4         76.8        15.5           7.7         0.0          19.2  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "0    38151.6\n",
      "1    53337.9\n",
      "2    79589.5\n",
      "3    59821.0\n",
      "4    70057.0\n",
      "Name: AvgIncome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Reading the demographics directly here and then loading it onto SQL first and then transforming it\n",
    "file_path1 = '/Users/tanvidineshnandu/Desktop/md_data_folder/nyc_census_tracts.csv'\n",
    "data = pd.read_csv(file_path1) \n",
    "\n",
    "print(data.head())\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "#Extract the unique list of boroughs from the 'data' DataFrame and remove duplicates.\n",
    "boroughs_data = data[['Borough']].drop_duplicates()\n",
    "\n",
    "#Aggregate demographic data by borough. Calculate the total population, total number of men, and total number of women.\n",
    "demographics_agg = data.groupby('Borough').agg(TotalPop=('TotalPop', 'sum'),\n",
    "                                               Men=('Men', 'sum'),\n",
    "                                               Women=('Women', 'sum')).reset_index()\n",
    "\n",
    "#Aggregate race and ethnicity data by borough\n",
    "race_ethnicity_agg = data.groupby('Borough').agg(TotalHispanic=('Hispanic', 'sum'),\n",
    "                                                 TotalWhite=('White', 'sum'),\n",
    "                                                 TotalBlack=('Black', 'sum'),\n",
    "                                                 TotalNative=('Native', 'sum'),\n",
    "                                                 TotalAsian=('Asian', 'sum')).reset_index()\n",
    "\n",
    "#Aggregate economic indicators by borough\n",
    "economic_indicators_agg = data.groupby('Borough').agg(AvgIncome=('Income', 'mean'),\n",
    "                                                      TotalEmployed=('Employed', 'sum'),\n",
    "                                                      TotalUnemployed=('Unemployment', 'sum')).reset_index()\n",
    "\n",
    "# Round the AvgIncome in the economic_indicators_agg DataFrame to one decimal place\n",
    "economic_indicators_agg['AvgIncome'] = economic_indicators_agg['AvgIncome'].round(1)\n",
    "\n",
    "# After rounding\n",
    "print(economic_indicators_agg['AvgIncome'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Crime Stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading and inserting 'crime data files' directly on SQL and transforming them\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Database connection URL\n",
    "DATABASE_URL = \"postgresql://postgres:123@localhost:5432/nyc_projectmd\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "#Our crime data had precinct numbers, but not zipcodes; \n",
    "#so we connected it with the precinct data (parking lot data) which had both zipcodes and boroughs\n",
    "\n",
    "# Read and insert latitude and longitude data -- this is required for mapping it on the heat map\n",
    "file_path_lat_long = '/Users/tanvidineshnandu/Desktop/md_data_folder/us_lat_long.csv'\n",
    "data_lat_long = pd.read_csv(file_path_lat_long)\n",
    "data_lat_long.columns = ['zipcode', 'latitude', 'longitude']  # Ensure column names are lowercase\n",
    "data_lat_long.to_sql('lat_long', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Read and insert precinct data \n",
    "file_path_precinct = '/Users/tanvidineshnandu/Desktop/md_data_folder/DPR_ParkingLots_001_20240325.csv'\n",
    "data_precinct = pd.read_csv(file_path_precinct, usecols=['PRECINCT', 'ZIPCODE', 'BOROUGH'])\n",
    "data_precinct.columns = ['precinct', 'zipcode', 'borough']  # Ensure column names are lowercase\n",
    "data_precinct.to_sql('precinct', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Read crime data, melt it, and insert\n",
    "file_path_crime = '/Users/tanvidineshnandu/Desktop/md_data_folder/crimedata.csv'\n",
    "data_crime = pd.read_csv(file_path_crime)\n",
    "df_melted = data_crime.melt(id_vars=[\"PCT\", \"CRIME\"], var_name=\"YEAR\", value_name=\"DATA\")\n",
    "df_melted.columns = ['pct', 'crime', 'year', 'data']  # Ensure column names are lowercase\n",
    "df_melted.to_sql('crime_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>average_crime_data</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10004</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>11693</td>\n",
       "      <td>150.4</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>11693</td>\n",
       "      <td>150.4</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>11693</td>\n",
       "      <td>150.4</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>11693</td>\n",
       "      <td>150.4</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>11693</td>\n",
       "      <td>150.4</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>848 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    zipcode  average_crime_data    borough\n",
       "0     10004               505.0  Manhattan\n",
       "1     10004               505.0  Manhattan\n",
       "2     10004               505.0  Manhattan\n",
       "3     10004               505.0  Manhattan\n",
       "4     10004               505.0  Manhattan\n",
       "..      ...                 ...        ...\n",
       "843   11693               150.4     Queens\n",
       "844   11693               150.4     Queens\n",
       "845   11693               150.4     Queens\n",
       "846   11693               150.4     Queens\n",
       "847   11693               150.4     Queens\n",
       "\n",
       "[848 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading and inserting crime data files directly on SQL and transforming them\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS crime_statistics AS\n",
    "        SELECT\n",
    "            c.pct,\n",
    "            c.crime,\n",
    "            c.year,\n",
    "            c.data,\n",
    "            p.zipcode,\n",
    "            p.borough\n",
    "        FROM\n",
    "            crime_data c\n",
    "        JOIN\n",
    "            precinct p ON c.pct = p.precinct;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Doing Borough Mapping to Update borough names\n",
    "    borough_updates = {\n",
    "        \"X\": \"The Bronx\",\n",
    "        \"B\": \"Brooklyn\",\n",
    "        \"M\": \"Manhattan\",\n",
    "        \"Q\": \"Queens\",\n",
    "        \"R\": \"Staten Island\"\n",
    "    }\n",
    "\n",
    "    for key, value in borough_updates.items():\n",
    "        conn.execute(text(\"UPDATE crime_statistics SET borough = :borough WHERE borough = :key;\"), {\"borough\": value, \"key\": key})\n",
    "\n",
    "# Normalize zipcodes\n",
    "with engine.begin() as conn:\n",
    "    df = pd.read_sql(\"SELECT * FROM crime_statistics;\", con=conn)\n",
    "    df_normalized = df.drop('zipcode', axis=1).join(\n",
    "        df['zipcode'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('zipcode')\n",
    "    )\n",
    "    df_normalized.to_sql('crime_statistics_expanded', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Create a new table to store aggregated data\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS final_crime_statistics (\n",
    "            zipcode VARCHAR(10),\n",
    "            average_crime_data FLOAT,\n",
    "            borough VARCHAR(255)\n",
    "        );\n",
    "    \"\"\"))\n",
    "\n",
    "    # Insert aggregated data into the new table\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO final_crime_statistics (zipcode, average_crime_data, borough)\n",
    "        SELECT\n",
    "            zipcode,\n",
    "            ROUND(AVG(data)::numeric, 1) AS average_crime_data,\n",
    "            MAX(borough) AS borough\n",
    "        FROM\n",
    "            crime_statistics_expanded\n",
    "        GROUP BY\n",
    "            zipcode;\n",
    "    \"\"\"))\n",
    "\n",
    "# Display the final query result from the aggregated data table\n",
    "df_final = pd.read_sql(\"SELECT * FROM final_crime_statistics ORDER BY zipcode ASC;\", con=engine)\n",
    "\n",
    "df_final #our final crime data - which we will plot on the heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      zip_code                                        school_name    borough\n",
       "0       10467  Bronx High School for Writing and Communicatio...      Bronx\n",
       "1       10023  The Maxine Greene High School for Imaginative ...  Manhattan\n",
       "2       11420                           Epic High School - South     Queens\n",
       "3       10457                        Eagle Academy for Young Men      Bronx\n",
       "4       10040                                The College Academy  Manhattan\n",
       "..        ...                                                ...        ...\n",
       "422     10460               Fannie Lou Hamer Freedom High School      Bronx\n",
       "423     11201                 Brooklyn International High School   Brooklyn\n",
       "424     11691  Academy of Medical Technology: A College Board...     Queens\n",
       "425     11206                          The Brooklyn Latin School   Brooklyn\n",
       "426     10034          High School for Excellence and Innovation  Manhattan\n",
       "\n",
       "[427 rows x 3 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning 'high_school' data file, creating SQL Table wrapped in text\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Ensure the 'Borough' column is in title case\n",
    "high_school_df['Borough'] = high_school_df['Borough'].str.title()\n",
    "\n",
    "# Connection string to connect to PostgreSQL\n",
    "db_connection_url = 'postgresql://postgres:123@localhost:5432/nyc_projectmd'\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# SQL statement to create the high_schools table, wrapped in text()\n",
    "create_table_stmt = text(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS high_schools (\n",
    "    zip_code VARCHAR(255) NOT NULL,\n",
    "    borough VARCHAR(255) NOT NULL,\n",
    "    school_name VARCHAR(255) NOT NULL,\n",
    "    school_id SERIAL PRIMARY KEY);\n",
    "\"\"\")\n",
    "\n",
    "# Execute the statement to create the table if it doesn't exist\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_table_stmt)\n",
    "    \n",
    "# Select and rename columns from the DataFrame\n",
    "high_schools = high_school_df[['postcode', 'school_name', 'Borough']].drop_duplicates()\n",
    "high_schools.columns = ['zip_code', 'school_name', 'borough']\n",
    "high_schools.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              name    zip    borough\n",
       "0    115th Street  10026  Manhattan\n",
       "1    125th Street  10035  Manhattan\n",
       "2     53rd Street  10019  Manhattan\n",
       "3     58th Street  10022  Manhattan\n",
       "4     67th Street  10065  Manhattan\n",
       "..            ...    ...        ...\n",
       "211     Sunnyside  11104     Queens\n",
       "212    Whitestone  11357     Queens\n",
       "213  Windsor Park  11364     Queens\n",
       "214     Woodhaven  11421     Queens\n",
       "215      Woodside  11377     Queens\n",
       "\n",
       "[216 rows x 3 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Working on Data Cleaning the 'library_df'\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import inspect  # Import the inspect module\n",
    "\n",
    "# Define the mapping of BOROCODE to borough names\n",
    "borough_map = {\n",
    "    1: 'Manhattan',\n",
    "    2: 'Bronx',\n",
    "    3: 'Brooklyn',\n",
    "    4: 'Queens',\n",
    "    5: 'Staten Island'\n",
    "}\n",
    "\n",
    "# Map BOROCODE to borough names and create a new 'borough' column\n",
    "library_df['borough'] = library_df['BOROCODE'].map(borough_map)\n",
    "\n",
    "# Connection string to your PostgreSQL database\n",
    "db_connection_url = 'postgresql://postgres:123@localhost:5432/nyc_projectmd'\n",
    "\n",
    "# Create an engine that connects to the PostgreSQL server\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Check if the 'library' table exists, and if not, create it\n",
    "inspector = inspect(engine)  # Create an inspector object\n",
    "\n",
    "# SQL statement to create the library table, wrapped in text()\n",
    "create_table_stmt = text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS library (\n",
    "        library_id SERIAL PRIMARY KEY,\n",
    "        name VARCHAR(255) NOT NULL,\n",
    "        zip VARCHAR(10) NOT NULL,\n",
    "        borough VARCHAR(255) NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Execute the statement to create the table if it doesn't exist\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_table_stmt)\n",
    "\n",
    "# Prepare the DataFrame for insertion\n",
    "# Keep only necessary columns and ensure no duplicates\n",
    "library_df = library_df[['NAME', 'ZIP', 'borough']].drop_duplicates()\n",
    "\n",
    "# Rename columns to match the SQL table definition\n",
    "library_df.columns = ['name', 'zip', 'borough'] \n",
    "library_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transportation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x13763ec50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subway Stations - Clean the data, prepare as needed, create table. \n",
    "\n",
    "# Map borough abbreviations to full names\n",
    "borough_map = {\n",
    "    'Q': 'Queens',\n",
    "    'M': 'Manhattan',\n",
    "    'Bk': 'Brooklyn',\n",
    "    'Bx': 'Bronx',\n",
    "    'S': 'Staten Island'\n",
    "}\n",
    "subway_df['Borough'] = subway_df['Borough'].map(borough_map)\n",
    "\n",
    "# Select and rename the required columns\n",
    "subway_df = subway_df[['Borough', 'Stop Name', 'Line', 'ADA']].copy()\n",
    "subway_df.columns = ['borough', 'station_name', 'line', 'ada_accessible']\n",
    "\n",
    "# Convert 'ada_accessible' from integers to boolean\n",
    "subway_df['ada_accessible'] = subway_df['ada_accessible'].astype(bool)\n",
    "\n",
    "# Connection string to your PostgreSQL database\n",
    "db_connection_url = 'postgresql://postgres:123@localhost:5432/nyc_projectmd' \n",
    "\n",
    "# Create an engine that connects to the PostgreSQL server\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Prepare the SQL statement for creating the table \n",
    "create_table_stmt = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS subway_stations (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        borough VARCHAR(255),\n",
    "        station_name VARCHAR(255) NOT NULL,\n",
    "        line VARCHAR(255),\n",
    "        ada_accessible BOOLEAN\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "# Execute the create table statement\n",
    "engine.execute(create_table_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x137631390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New York's Transportation Data - Clean the data, prepare as needed, create table. \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Assuming 'Borough' contains full names, select transportation-related columns\n",
    "transportation_cols = ['Borough', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp', 'WorkAtHome', 'MeanCommute']\n",
    "\n",
    "# Filter the dataframe to include only transportation-related columns\n",
    "transportation_df = demo_df[transportation_cols].copy()\n",
    "\n",
    "# Group by 'Borough' and calculate the mean for each transportation-related column\n",
    "borough_transportation = transportation_df.groupby('Borough', as_index=False).mean()\n",
    "\n",
    "# Rename columns to match your database schema, if necessary\n",
    "borough_transportation.columns = ['borough', 'drive', 'carpool', 'transit', 'walk', 'other_transp', 'work_at_home', 'mean_commute']\n",
    "\n",
    "# Connection string to your PostgreSQL database\n",
    "db_connection_url = 'postgresql://postgres:123@localhost:5432/nyc_projectmd'\n",
    "\n",
    "# Create an engine that connects to the PostgreSQL server\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Prepare the SQL statement for creating the table \n",
    "create_table_stmt = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS nyc_borough_transportation (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        borough VARCHAR(255),\n",
    "        drive NUMERIC,\n",
    "        carpool NUMERIC,\n",
    "        transit NUMERIC,\n",
    "        walk NUMERIC,\n",
    "        other_transp NUMERIC,\n",
    "        work_at_home NUMERIC,\n",
    "        mean_commute NUMERIC\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "# Execute the create table statement\n",
    "engine.execute(create_table_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RequestID', 'Boro', 'Yr', 'M', 'D', 'HH', 'MM', 'Vol', 'SegmentID',\n",
      "       'WktGeom', 'street', 'fromSt', 'toSt', 'Direction'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Working on the NY's traffic data - borough_traffic_averages - data cleaning and transformation\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Ensure that the column names are correct\n",
    "print(borough_traffic_averages.columns)\n",
    "\n",
    "# Combine year, month, day, hour, and minute into a datetime column\n",
    "# Use the format parameter to specify the format of our datetime columns\n",
    "borough_traffic_averages['datetime'] = pd.to_datetime(borough_traffic_averages['Yr'].astype(str) + '-' + borough_traffic_averages['M'].astype(str) + '-' + \n",
    "                                borough_traffic_averages['D'].astype(str) + ' ' + borough_traffic_averages['HH'].astype(str) + ':' + \n",
    "                                borough_traffic_averages['MM'].astype(str), format='%Y-%m-%d %H:%M')\n",
    "\n",
    "# Set the 'datetime' column as the DataFrame index\n",
    "borough_traffic_averages.set_index('datetime', inplace=True)\n",
    "\n",
    "# Group the data by borough and resample to get daily averages\n",
    "daily_avg = borough_traffic_averages.groupby('Boro').resample('D')['Vol'].mean().reset_index(name='daily_avg')\n",
    "\n",
    "# Calculate the overall average for each borough\n",
    "borough_daily_avg = daily_avg.groupby('Boro')['daily_avg'].mean().reset_index()\n",
    "\n",
    "# Rename the columns as per the schema of the database table\n",
    "borough_daily_avg.columns = ['borough', 'daily_traffic_volume_avg']\n",
    "\n",
    "# Connection string to your PostgreSQL database\n",
    "db_connection_url = 'postgresql://postgres:123@localhost:5432/nyc_projectmd' \n",
    "\n",
    "# Create an engine that connects to the PostgreSQL server\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# SQL statement for creating the table \n",
    "create_table_stmt = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS borough_traffic_averages (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    borough VARCHAR(255),\n",
    "    daily_traffic_volume_avg NUMERIC\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the create table statement\n",
    "engine.execute(create_table_stmt)\n",
    "\n",
    "# Insert the aggregated DataFrame into the PostgreSQL table\n",
    "borough_daily_avg.to_sql(name='borough_traffic_averages', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Facility Type', 'Borough', 'Facility Name', 'Cross Streets', 'Phone',\n",
      "       'Location 1'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows before dropping: 670\n",
      "Number of duplicate rows dropped = 78\n",
      "Facility Type    0\n",
      "Borough          0\n",
      "Facility Name    0\n",
      "dtype: int64\n",
      "<bound method NDFrame.head of           Facility Type    Borough                             Facility Name\n",
      "0   Child Health Center  Manhattan                     La Clinica Del Barrio\n",
      "1   Acute Care Hospital     Queens                  Elmhurst Hospital Center\n",
      "2   Child Health Center   Brooklyn     Ida G. Israel Community Health Center\n",
      "3   Child Health Center     Queens      South Queens Community Health Center\n",
      "4   Child Health Center      Bronx        Melrose Houses Child Health Clinic\n",
      "..                  ...        ...                                       ...\n",
      "73  Child Health Center   Brooklyn          Bushwick Community Health Center\n",
      "74  Child Health Center  Manhattan                  Bellevue Hospital Center\n",
      "75  Child Health Center     Queens              Ridgewood Communicare Clinic\n",
      "76  Child Health Center  Manhattan           Smith Communicare Health Center\n",
      "77  Child Health Center      Bronx  Morrisania Diagnostic & Treatment Center\n",
      "\n",
      "[78 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(hospitals_df.columns)\n",
    "\n",
    "#Drop columns that we dont need\n",
    "columns_to_drop = ['Cross Streets', 'Phone', 'Location 1']\n",
    "hospitals_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "hospitals_df\n",
    "\n",
    "# Drop duplicate rows based on 'Facility Type' and 'Facility Name'\n",
    "print(\"Number of duplicate rows before dropping:\", restaurants_df.shape[0])\n",
    "hospitals_df = hospitals_df.drop_duplicates(subset=['Facility Type', 'Facility Name', 'Borough'])\n",
    "print(\"Number of duplicate rows dropped =\", hospitals_df.shape[0])\n",
    "\n",
    "#Checking for null values\n",
    "null_values = hospitals_df.isnull().sum()\n",
    "print(null_values)\n",
    "\n",
    "print(hospitals_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Parks' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acres</th>\n",
       "      <th>address</th>\n",
       "      <th>borough</th>\n",
       "      <th>class</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>1.19</td>\n",
       "      <td>4802 TILDEN AVENUE</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>PARK</td>\n",
       "      <td>11203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>20.132</td>\n",
       "      <td>570 WEST 214 STREET</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>PARK</td>\n",
       "      <td>10034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>0.98</td>\n",
       "      <td>204-08 203 STREET</td>\n",
       "      <td>Queens</td>\n",
       "      <td>PARK</td>\n",
       "      <td>11412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>6.1</td>\n",
       "      <td>200 CITY ISLAND AV</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>PARK</td>\n",
       "      <td>10464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>20.867</td>\n",
       "      <td>665 WEST 252 STREET</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>PARK</td>\n",
       "      <td>10471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acres              address    borough class zipcode\n",
       "2039    1.19   4802 TILDEN AVENUE   Brooklyn  PARK   11203\n",
       "2040  20.132  570 WEST 214 STREET  Manhattan  PARK   10034\n",
       "2041    0.98    204-08 203 STREET     Queens  PARK   11412\n",
       "2045     6.1   200 CITY ISLAND AV      Bronx  PARK   10464\n",
       "2046  20.867  665 WEST 252 STREET      Bronx  PARK   10471"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parks_df.head()\n",
    "\n",
    "#check Null Values\n",
    "null_percent= parks_df.isnull().sum()/len(parks_df)\n",
    "null_percent\n",
    "\n",
    "#Drop columns that were null based on the % we got above\n",
    "columns_to_drop= null_percent[null_percent>=0.7].index\n",
    "\n",
    "parks_df_cleaned = parks_df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "#dimension of the dataframe\n",
    "parks_df_cleaned.shape\n",
    "\n",
    "parks_df_cleaned.head()\n",
    "\n",
    "#BOROUGH MAPPING\n",
    "parks_df_cleaned['BOROUGH'].value_counts()\n",
    "parks_df_cleaned.columns= [col.lower() for col in parks_df_cleaned.columns]\n",
    "borough_mapping = {\n",
    "    'B': 'Brooklyn', \n",
    "    'Q': 'Queens', \n",
    "    'X': 'Bronx', \n",
    "    'M': 'Manhattan', \n",
    "    'R': 'Staten Island'}\n",
    "\n",
    "parks_df_cleaned['borough'] = parks_df_cleaned['borough'].map(borough_mapping)\n",
    "\n",
    "parks_df_cleaned.head()\n",
    "\n",
    "parks_df_cleaned['borough'].value_counts()\n",
    "\n",
    "#zipcodes' column needed to be filtered using regex, and a new zipcode column is created\n",
    "import numpy as np\n",
    "zip_code_regex = r'^\\d{5}(-\\d{4})?$'\n",
    "\n",
    "\n",
    "# Replace entries that don't match the zip code pattern with NaN\n",
    "parks_df_cleaned['zipcode'] = np.where(parks_df_cleaned['zipcode'].str.match(zip_code_regex), parks_df_cleaned['zipcode'], np.nan)\n",
    "parks_df_cleaned.columns\n",
    "\n",
    "#typecasting\n",
    "parks_df_cleaned['zipcode']= parks_df_cleaned['zipcode'].astype(str).str[:5]\n",
    "\n",
    "#dropped irrelevant columns that are not needed in visualization \n",
    "parks_df_cleaned = parks_df_cleaned.drop(['acquisitiondate','gispropnum', 'globalid', 'jurisdiction', 'location', 'mapped',\n",
    "       'name311', 'nys_assembly', 'nys_senate', 'objectid', 'omppropid', 'eapply', 'gisobjid',\n",
    "       'parentid', 'permit', 'permitdistrict', 'permitparent', 'pip_ratable',\n",
    "       'precinct', 'retired', 'signname', 'subcategory', 'typecategory', 'url',\n",
    "       'us_congress', 'waterfront'], axis=1)\n",
    "\n",
    "\n",
    "#Data Cleaning \n",
    "final_parks=parks_df_cleaned.drop(['communityboard','councildistrict','department','multipolygon'],axis=1)\n",
    "\n",
    "final_parks.columns\n",
    "\n",
    "final_parks['zipcode'].replace(\"nan\",None,inplace=True)\n",
    "\n",
    "final_parks['class']='PARK'\n",
    "\n",
    "final_parks['acres'] = final_parks['acres'].astype(str)\n",
    "\n",
    "\n",
    "final_parks.dropna(inplace=True)\n",
    "\n",
    "def cleaning_data(x):\n",
    "    if len(x)>40:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "final_parks.head()\n",
    "\n",
    "final_parks['acres']= final_parks['acres'].apply(cleaning_data)\n",
    "\n",
    "final_parks.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Housing Prices Data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zipcode State         City          CountyName  Bedrooms      2/29/24  \\\n",
      "0     8701    NJ     Lakewood        Ocean County         1  147211.5873   \n",
      "1    11368    NY     New York       Queens County         1  295613.6493   \n",
      "2    77084    TX      Houston       Harris County         1  110530.4080   \n",
      "3    11385    NY     New York       Queens County         1  518884.6461   \n",
      "4    90011    CA  Los Angeles  Los Angeles County         1  460339.2929   \n",
      "\n",
      "       1/31/24     12/31/23     11/30/23     10/31/23      9/30/23  \n",
      "0  145761.3242  143710.5982  141378.1497  139274.8913  137655.5525  \n",
      "1  296021.0357  297250.8751  299181.4487  299777.6779  297951.2679  \n",
      "2  111361.6061  111909.7233  112663.5152  113229.4815  113294.4901  \n",
      "3  520898.9310  520370.0988  521372.5027  522187.8711  525545.8851  \n",
      "4  466610.4360  468951.2469  467966.2946  465212.3014  462102.1029  \n"
     ]
    }
   ],
   "source": [
    "all_homes.head()\n",
    "# Checking number of rows in allb \n",
    "len(all_homes),len(one_bedroom), len(two_bedroom), len(three_bedroom), len(four_bedroom), len(five_bedroom)\n",
    "\n",
    "\n",
    "#selecting required columns\n",
    "columns_to_select = ['RegionName', 'State', 'City', 'CountyName', 'Bedrooms',\n",
    "                     '2/29/24', '1/31/24', '12/31/23',\n",
    "                     '11/30/23', '10/31/23', '9/30/23']\n",
    "\n",
    "\n",
    "one_bedroom_final = one_bedroom[columns_to_select]\n",
    "two_bedroom_final = two_bedroom[columns_to_select]\n",
    "three_bedroom_final = three_bedroom[columns_to_select]\n",
    "four_bedroom_final = four_bedroom[columns_to_select]\n",
    "five_bedroom_final = five_bedroom[columns_to_select]\n",
    "\n",
    "#Had to use different column names for this dataframe only since column names were different\n",
    "all_homes_final = all_homes[['RegionName', 'State', 'City', 'CountyName',\n",
    "                     '2024-02-29', '2024-01-31', '2023-12-31',\n",
    "                     '2023-11-30', '2023-10-31', '2023-09-30']]\n",
    "\n",
    "\n",
    "\n",
    "#Renaming columns\n",
    "one_bedroom_final = one_bedroom_final.rename(columns={'RegionName': 'Zipcode'})\n",
    "two_bedroom_final = two_bedroom_final.rename(columns={'RegionName': 'Zipcode'})\n",
    "three_bedroom_final = three_bedroom_final.rename(columns={'RegionName': 'Zipcode'})\n",
    "four_bedroom_final = four_bedroom_final.rename(columns={'RegionName': 'Zipcode'})\n",
    "five_bedroom_final = five_bedroom_final.rename(columns={'RegionName': 'Zipcode'})\n",
    "all_homes_final = all_homes_final.rename(columns={'RegionName': 'Zipcode', '2024-02-29':'2/29/24',\n",
    "                                                 '2024-01-31': '1/31/24', '2023-12-31': '12/31/23',\n",
    "                                                 '2023-11-30': '11/30/23', '2023-10-31': '10/31/23',\n",
    "                                                 '2023-09-30': '9/30/23'})\n",
    "\n",
    "print(one_bedroom_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Zipcode', 'State', 'City', 'CountyName', 'Bedrooms', '2024-02',\n",
      "       '2024-01', '2023-12', '2023-11', '2023-10', '2023-09'],\n",
      "      dtype='object')\n",
      "Index(['Zipcode', '2024-02', '2024-01', '2023-12', '2023-11', '2023-10',\n",
      "       '2023-09'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Merging the 5 tables (one_bedroom, two_bedroom, etc....) into one table; all tables except all_homes_final\n",
    "all_homes_by_bedrooms = pd.concat([one_bedroom_final, two_bedroom_final,\n",
    "                                   three_bedroom_final, four_bedroom_final, five_bedroom_final],\n",
    "                                  ignore_index=True)\n",
    "\n",
    "# Checking to ensure all values were included\n",
    "len(one_bedroom) + len(two_bedroom) + len(three_bedroom) + len(four_bedroom) + len(five_bedroom) == len(all_homes_by_bedrooms)\n",
    "\n",
    "#Number of missing values by column\n",
    "all_homes_by_bedrooms.isna().sum()\n",
    "\n",
    "all_homes_final.isna().sum()\n",
    "\n",
    "# Filtering for NY zipcodes only\n",
    "all_homes_by_bedrooms = all_homes_by_bedrooms[all_homes_by_bedrooms['State'] == 'NY']\n",
    "all_homes_final = all_homes_final[['Zipcode','2/29/24', '1/31/24', '12/31/23','11/30/23', '10/31/23', '9/30/23']]\n",
    "\n",
    "# Imputing value of 0 for all missing values\n",
    "all_homes_by_bedrooms.fillna(0, inplace=True)\n",
    "all_homes_final.fillna(0, inplace=True)\n",
    "\n",
    "#Changing column name to date data type for using in graphs\n",
    "new_column_names = []\n",
    "for col in all_homes_by_bedrooms.columns:\n",
    "    try:\n",
    "        # Convert to datetime\n",
    "        col_as_datetime = pd.to_datetime(col)\n",
    "        # Format to \"YYYY-MM\" and append to new column names list\n",
    "        new_column_names.append(col_as_datetime.strftime('%Y-%m'))\n",
    "    except ValueError:\n",
    "        # If conversion fails, keep the original column name\n",
    "        new_column_names.append(col)\n",
    "\n",
    "# Assign the new column names back to the DataFrame\n",
    "all_homes_by_bedrooms.columns = new_column_names\n",
    "\n",
    "# Display the DataFrame to verify the change\n",
    "print(all_homes_by_bedrooms.columns)\n",
    "\n",
    "\n",
    "\n",
    "new_column_names = []\n",
    "for col in all_homes_final.columns:\n",
    "    try:\n",
    "        # Convert to datetime\n",
    "        col_as_datetime = pd.to_datetime(col)\n",
    "        # Format to \"YYYY-MM\" and append to new column names list\n",
    "        new_column_names.append(col_as_datetime.strftime('%Y-%m'))\n",
    "    except ValueError:\n",
    "        # If conversion fails, keep the original column name\n",
    "        new_column_names.append(col)\n",
    "\n",
    "# Assign the new column names back to the DataFrame\n",
    "all_homes_final.columns = new_column_names\n",
    "\n",
    "# Display the DataFrame to verify the change\n",
    "print(all_homes_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing same steps as above for forecasted house prices dataset - Importing dataset\n",
    "all_homes_forecast.head()\n",
    "#\n",
    "#Selecting relevant columns\n",
    "all_homes_forecast = all_homes_forecast[['RegionName', 'State','BaseDate',\n",
    "                                          '2024-03-31', '2024-05-31', '2025-02-28']]\n",
    "\n",
    "#renaming Columns\n",
    "all_homes_forecast = all_homes_forecast.rename(columns={'RegionName': 'zipcode', 'BaseDate': 'basedate', '2024-03-31':'2024-03',\n",
    "                                                 '2024-05-31': '2024-05', '2025-02-28': '2025-02'})\n",
    "\n",
    "#Filtering for NY Zip Codes \n",
    "all_homes_forecast = all_homes_forecast[all_homes_forecast['State'] == 'NY']\n",
    "\n",
    "all_homes_forecast\n",
    "\n",
    "#Checking missing values\n",
    "all_homes_forecast.isna().sum()\n",
    "\n",
    "#Changing data type of BaseDate column to data\n",
    "all_homes_forecast.dtypes\n",
    "\n",
    "#changing structure of basedate for a better format\n",
    "all_homes_forecast['basedate'] = pd.to_datetime(all_homes_forecast['basedate']).dt.strftime('%m-%d-%Y')\n",
    "\n",
    "all_homes_forecast\n",
    "\n",
    "#Selecting only relevant columns\n",
    "all_homes_forecast = all_homes_forecast[['zipcode','basedate',\n",
    "                                          '2024-03', '2024-05', '2025-02']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       zipcode        2024-02       2024-01       2023-12       2023-11  \\\n",
       "4       11385    2927.157063   2901.151309   2866.434699   2843.439019   \n",
       "6       11208    2677.507937   2676.152092   2647.161027   2634.880571   \n",
       "13      11236    2624.333333   2527.692271   2438.186951   2430.381784   \n",
       "14      10467    2049.541667   2063.901324   2038.555373   2045.855582   \n",
       "15      11373    2644.183333   2634.409904   2635.389306   2617.415381   \n",
       "...       ...            ...           ...           ...           ...   \n",
       "6653    11932   57708.291667  56791.814849      0.000000      0.000000   \n",
       "6654    11930   74222.200000  76711.380698  70816.986151  67210.135393   \n",
       "6656    11959   50000.000000  44893.801851      0.000000      0.000000   \n",
       "6657    11962  106250.000000  98928.753262      0.000000      0.000000   \n",
       "6663    10004    4781.527778   4734.681086   4730.962801   4703.536465   \n",
       "\n",
       "           2023-10       2023-09  \n",
       "4      2821.722613   2818.173612  \n",
       "6      2564.938472   2545.574934  \n",
       "13     2378.784781   2346.971466  \n",
       "14     1982.157742   1927.609073  \n",
       "15     2623.307388   2597.244253  \n",
       "...            ...           ...  \n",
       "6653      0.000000      0.000000  \n",
       "6654  65200.967242  71659.738593  \n",
       "6656      0.000000      0.000000  \n",
       "6657      0.000000      0.000000  \n",
       "6663   4693.885823   4600.877285  \n",
       "\n",
       "[308 rows x 7 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeating process for All_homes_observed_rent\n",
    "all_homes_observed_rent.columns\n",
    "\n",
    "#Filter for NY data\n",
    "all_homes_observed_rent = all_homes_observed_rent[all_homes_observed_rent['State'] == 'NY']\n",
    "\n",
    "all_homes_observed_rent.head()\n",
    "\n",
    "#keeping only relevant columns\n",
    "all_homes_observed_rent = all_homes_observed_rent[['RegionName',\n",
    "                                               '2024-02-29', '2024-01-31', '2023-12-31',\n",
    "                                               '2023-11-30', '2023-10-31', '2023-09-30']]\n",
    "\n",
    "#Renaming Columns\n",
    "all_homes_observed_rent.columns = ['zipcode','2024-02','2024-01', '2023-12', '2023-11','2023-10','2023-09' ]\n",
    "\n",
    "#imputing value of 0 for missing data\n",
    "all_homes_observed_rent.fillna(0, inplace=True)\n",
    "all_homes_observed_rent.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Location Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Borough', 'zipcode'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>borough_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>10453</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>10458</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>10451</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>10454</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>10463</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11420</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11378</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11428</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11421</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11429</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    borough  zipcode  borough_id\n",
       "0     Bronx    10453         2.0\n",
       "1     Bronx    10458         2.0\n",
       "2     Bronx    10451         2.0\n",
       "3     Bronx    10454         2.0\n",
       "4     Bronx    10463         2.0\n",
       "..      ...      ...         ...\n",
       "173  Queens    11420         4.0\n",
       "174  Queens    11378         4.0\n",
       "175  Queens    11428         4.0\n",
       "176  Queens    11421         4.0\n",
       "177  Queens    11429         4.0\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the Location Data\n",
    "\n",
    "#Check the data for usa's zip to borough dataset for null values, clean if needed. \n",
    "null_values = nyc_zip_borough_df.isnull().sum()\n",
    "null_values\n",
    "\n",
    "nyc_zip_borough_df\n",
    "\n",
    "#Renaming the 'measurement' column to 'zipcode'\n",
    "nyc_zip_borough_df = nyc_zip_borough_df.rename(columns={'measurement': 'zipcode'})\n",
    "\n",
    "#Dropping the 'neighborhood' column\n",
    "nyc_zip_borough_df = nyc_zip_borough_df.drop(columns=['Neighborhood'])\n",
    "\n",
    "#Verify the changes\n",
    "print(nyc_zip_borough_df.columns)\n",
    "\n",
    "#renaming columns wherver needed to make merge process easier \n",
    "nyc_zip_borough_df = nyc_zip_borough_df.rename(columns={'Borough': 'borough'})\n",
    "\n",
    "#left join the nyc_zip_borough_df to the borough_master_df and call it borough_zip\n",
    "borough_zip = pd.merge(nyc_zip_borough_df, borough_master_df, on='borough', how='left')\n",
    "borough_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entertainmnet and Recreation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows before dropping: 666\n",
      "Number of duplicate rows dropped = 663\n"
     ]
    }
   ],
   "source": [
    "#Check the restaurant dataset for null values, clean if needed. \n",
    "restaurants_df.head\n",
    "\n",
    "#View what all columns have null values \n",
    "null_values = restaurants_df.isnull().sum()\n",
    "null_values\n",
    "\n",
    "#Out of all the columns with Null Values, we will only need the 'Rating' column in the final dashboard, so drop the rows with Null values in Ratings\n",
    "restaurants_df.dropna(subset=['Rating'], inplace=True)\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop = ['URL', 'Rating Count', 'Detailed Ratings', 'Price Category', 'Address', 'Lat', 'Lon']\n",
    "restaurants_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Drop duplicate rows based on 'Name' and 'ZipCode'\n",
    "print(\"Number of duplicate rows before dropping:\", restaurants_df.shape[0])\n",
    "restaurants_df = restaurants_df.drop_duplicates(subset=['Name', 'ZipCode'])\n",
    "print(\"Number of duplicate rows dropped =\", restaurants_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the swimming pools dataset for null values, clean if needed. \n",
    "swimmingpool_df.columns\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop_pools = ['the_geom', 'OBJECTID', 'LOCATION', 'GISPROPNUM', 'COUNCILDIS', 'POOLTYPE', 'SHAPE_STAr', 'SHAPE_STLe']\n",
    "swimmingpool_df.drop(columns=columns_to_drop_pools, inplace=True)\n",
    "swimmingpool_df.head\n",
    "\n",
    "#The Borough column needs to be updated to (B=Brooklyn, X=Bronx, M=Manhattan, Q=Queens,R=Staten Island(Richmond))\n",
    "borough_mapping = {\n",
    "    'B': 'Brooklyn',\n",
    "    'X': 'Bronx',\n",
    "    'M': 'Manhattan',\n",
    "    'Q': 'Queens',\n",
    "    'R': 'Staten Island'\n",
    "}\n",
    "\n",
    "swimmingpool_df['BOROUGH'] = swimmingpool_df['BOROUGH'].replace(borough_mapping)\n",
    "\n",
    "#checking for null values\n",
    "null_values = swimmingpool_df.isnull().sum()\n",
    "null_values\n",
    "\n",
    "swimmingpool_df = swimmingpool_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME    0\n",
       "ZIP     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the museums dataset for null values, clean if needed. \n",
    "museum_df\n",
    "museum_df.columns\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop_museums = ['the_geom', 'TEL', 'URL', 'ADRESS1', 'ADDRESS2', 'CITY']\n",
    "museum_df.drop(columns=columns_to_drop_museums, inplace=True)\n",
    "\n",
    "null_values = museum_df.isnull().sum()\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borough        0\n",
      "Market Name    0\n",
      "Zip Code       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check the farmers markets dataset for null values, clean if needed. \n",
    "markets_df.columns\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop_markets = ['Street Address', 'Community District', ' Cooking Demonstrations', 'Latitude', 'Longitude', 'Days of Operation', 'Hours of Operations', 'Season Begin', 'Season End', 'Accepts EBT', 'Distributes Health Bucks?', 'Open Year-Round', 'Location Point']\n",
    "markets_df.drop(columns=columns_to_drop_markets, inplace=True)\n",
    "markets_df.head\n",
    "\n",
    "#Check for Null values if any\n",
    "null_values = markets_df.isnull().sum()\n",
    "print(null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                       NAME    ZIP\n",
      "0      45th Street Theater  10036\n",
      "1      47th Street Theater  10036\n",
      "2                    59E59  10022\n",
      "3            Acorn Theater  10036\n",
      "4    Al Hirschfeld Theater  10036\n",
      "..                     ...    ...\n",
      "112       Westside Theater  10036\n",
      "113          Wings Theatre  10014\n",
      "114  Winter Garden Theatre  10019\n",
      "115           York Theatre  10022\n",
      "116      Delacorte Theater      0\n",
      "\n",
      "[117 rows x 2 columns]>\n",
      "Borough        0\n",
      "Market Name    0\n",
      "Zip Code       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check the theatres dataset for null values, clean if needed. \n",
    "theatres_df.columns\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop_theatres = ['the_geom', 'TEL', 'URL', 'ADDRESS1', 'ADDRES2', 'CITY']\n",
    "theatres_df.drop(columns=columns_to_drop_theatres, inplace=True)\n",
    "print (theatres_df.head)\n",
    "\n",
    "##Check for Null values if any\n",
    "null_values = markets_df.isnull().sum()\n",
    "print(null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           BOROUGH               NAME\n",
      "0           Queens     Rockaway Beach\n",
      "92        Brooklyn       Coney Island\n",
      "127          Bronx      Orchard Beach\n",
      "128       Brooklyn    Manhattan Beach\n",
      "156  Staten Island  Cedar Grove Beach\n",
      "157  Staten Island      Midland Beach\n",
      "158  Staten Island        South Beach\n",
      "166  Staten Island  Wolfes Pond Beach\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BOROUGH    0\n",
       "NAME       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the beach dataset for null values, clean if needed. \n",
    "beaches_df.head\n",
    "\n",
    "#Drop Columns \n",
    "columns_to_drop_beach = ['the_geom', 'SYSTEM', 'GISPROPNUM', 'SHAPE_STAr', 'SHAPE_STLe']\n",
    "beaches_df.drop(columns=columns_to_drop_beach, inplace=True)\n",
    "beaches_df.head\n",
    "\n",
    "#The Borough column needs to be updated to (B=Brooklyn, X=Bronx, M=Manhattan, Q=Queens,R=Staten Island(Richmond))\n",
    "borough_mapping = {\n",
    "    'B': 'Brooklyn',\n",
    "    'X': 'Bronx',\n",
    "    'M': 'Manhattan',\n",
    "    'Q': 'Queens',\n",
    "    'R': 'Staten Island'\n",
    "}\n",
    "\n",
    "beaches_df['BOROUGH'] = beaches_df['BOROUGH'].replace(borough_mapping)\n",
    "beaches_df\n",
    "\n",
    "#Since there are many duplicates, drop the duplicates to find just the unique combinations\n",
    "unique_beaches_df = beaches_df.drop_duplicates()\n",
    "unique_beaches_df\n",
    "\n",
    "print (unique_beaches_df)\n",
    "\n",
    "#Check for Null Values in the beach dataset\n",
    "null_values = beaches_df.isnull().sum()\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ADULT_BASEBALL</th>\n",
       "      <th>ADULT_FOOTBALL</th>\n",
       "      <th>ADULT_SOFTBALL</th>\n",
       "      <th>BASKETBALL</th>\n",
       "      <th>BOCCE</th>\n",
       "      <th>CRICKET</th>\n",
       "      <th>FLAGFOOTBALL</th>\n",
       "      <th>FRISBEE</th>\n",
       "      <th>HANDBALL</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_SOFTBALL</th>\n",
       "      <th>NETBALL</th>\n",
       "      <th>NONREGULATION_SOCCER</th>\n",
       "      <th>REGULATION_SOCCER</th>\n",
       "      <th>RUGBY</th>\n",
       "      <th>TENNIS</th>\n",
       "      <th>T_BALL</th>\n",
       "      <th>VOLLEYBALL</th>\n",
       "      <th>WHEELCHAIRFOOTBALL</th>\n",
       "      <th>YOUTH_FOOTBALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>44</td>\n",
       "      <td>115</td>\n",
       "      <td>165</td>\n",
       "      <td>534</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>121</td>\n",
       "      <td>110</td>\n",
       "      <td>695</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>14</td>\n",
       "      <td>164</td>\n",
       "      <td>39</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>101</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>127</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>122</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>86</td>\n",
       "      <td>18</td>\n",
       "      <td>172</td>\n",
       "      <td>385</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>622</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staten Island</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>236</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>343</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BOROUGH  ADULT_BASEBALL  ADULT_FOOTBALL  ADULT_SOFTBALL  BASKETBALL  \\\n",
       "0       Brooklyn              44             115             165         534   \n",
       "1      Manhattan              50              27             127         272   \n",
       "2         Queens              86              18             172         385   \n",
       "3  Staten Island               6               8              30          69   \n",
       "4          Bronx              36              12              72         236   \n",
       "\n",
       "  BOCCE  CRICKET FLAGFOOTBALL  FRISBEE  HANDBALL  ...  LL_SOFTBALL  NETBALL  \\\n",
       "0    17       25          121      110       695  ...          210       14   \n",
       "1     1        7            1       19       250  ...          126        1   \n",
       "2    12       33           12        4       622  ...          204        0   \n",
       "3     8        1           12        7        50  ...           38        0   \n",
       "4    12       16           13        2       343  ...           94        0   \n",
       "\n",
       "   NONREGULATION_SOCCER  REGULATION_SOCCER  RUGBY  TENNIS T_BALL  VOLLEYBALL  \\\n",
       "0                   164                 39     63     153    101          22   \n",
       "1                    88                 50     17     122     59          54   \n",
       "2                    60                 26      2     224     35          25   \n",
       "3                    15                  7      2      26      3           2   \n",
       "4                    42                 25      2      98     10           8   \n",
       "\n",
       "   WHEELCHAIRFOOTBALL  YOUTH_FOOTBALL  \n",
       "0                  26             139  \n",
       "1                   0              42  \n",
       "2                   1              25  \n",
       "3                   0              17  \n",
       "4                   0              16  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review Athletics Facitilies dataset to see what all datacleaning is needed\n",
    "athleticfacilities_df\n",
    "\n",
    "#Creating the subset DataFrame FOR Just the Sports and athletic facities\n",
    "subset_df = athleticfacilities_df[['ADULT_BASEBALL', 'ADULT_FOOTBALL', 'ADULT_SOFTBALL', 'BASKETBALL', 'BOCCE', 'CRICKET', 'FLAGFOOTBALL', 'FRISBEE', 'HANDBALL', 'HOCKEY', 'KICKBALL', 'LACROSSE', 'LL_BASEB_12ANDUNDER', 'LL_BASEB_13ANDOLDER', 'LL_SOFTBALL', 'NETBALL', 'NONREGULATION_SOCCER', 'REGULATION_SOCCER', 'RUGBY', 'TENNIS', 'T_BALL', 'VOLLEYBALL', 'WHEELCHAIRFOOTBALL', 'YOUTH_FOOTBALL', 'ZIPCODE', 'BOROUGH']]\n",
    "subset_df\n",
    "\n",
    "#Grouping the number of athletic facities by Borough (GroupBy Boroughs, Count the True in the Athletic Feilds)\n",
    "grouped_df_brgh = subset_df.groupby('BOROUGH').sum()\n",
    "grouped_df_brgh.reset_index(inplace=True)\n",
    "\n",
    "#dropping Zipcode column here (since counting boroughs)\n",
    "grouped_df_brgh.drop(columns=['ZIPCODE'], inplace=True)\n",
    "\n",
    "#The Borough column in 'grouped_df_brgh' needs to be updated to (B=Brooklyn, X=Bronx, M=Manhattan, Q=Queens,R=Staten Island(Richmond))\n",
    "borough_mapping = {\n",
    "    'B': 'Brooklyn',\n",
    "    'X': 'Bronx',\n",
    "    'M': 'Manhattan',\n",
    "    'Q': 'Queens',\n",
    "    'R': 'Staten Island'\n",
    "}\n",
    "\n",
    "grouped_df_brgh['BOROUGH'] = grouped_df_brgh['BOROUGH'].replace(borough_mapping)\n",
    "grouped_df_brgh #this is essentially a dataset of the frequency of each sport or game type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Average_Electricity_Charges</th>\n",
       "      <th>Other charges</th>\n",
       "      <th>Average_Cooking_Gas_Charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>4877.795864</td>\n",
       "      <td>2232.539056</td>\n",
       "      <td>235.210667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>3490.012865</td>\n",
       "      <td>1563.688601</td>\n",
       "      <td>139.817673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FHA</td>\n",
       "      <td>43.606214</td>\n",
       "      <td>34.000101</td>\n",
       "      <td>6.928506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>4882.858203</td>\n",
       "      <td>2233.868626</td>\n",
       "      <td>246.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>3379.769238</td>\n",
       "      <td>1530.277372</td>\n",
       "      <td>151.697575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>15670.242525</td>\n",
       "      <td>6821.951791</td>\n",
       "      <td>184.456653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Borough  Average_Electricity_Charges  Other charges  \\\n",
       "0          BRONX                  4877.795864    2232.539056   \n",
       "1       BROOKLYN                  3490.012865    1563.688601   \n",
       "2            FHA                    43.606214      34.000101   \n",
       "3      MANHATTAN                  4882.858203    2233.868626   \n",
       "5         QUEENS                  3379.769238    1530.277372   \n",
       "6  STATEN ISLAND                 15670.242525    6821.951791   \n",
       "\n",
       "   Average_Cooking_Gas_Charges  \n",
       "0                   235.210667  \n",
       "1                   139.817673  \n",
       "2                     6.928506  \n",
       "3                   246.002440  \n",
       "5                   151.697575  \n",
       "6                   184.456653  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the electricity consumption and cost dataset for null values, clean if needed. \n",
    "electricity_df.head\n",
    "\n",
    "#Grouping the data by 'Borough' and calculating the average of 'Current Charges' and 'Other charges'\n",
    "average_electricity_charges = electricity_df.groupby('Borough')[['Current Charges', 'Other charges']].mean()\n",
    "\n",
    "#Reset the index to have 'Borough' as a column again\n",
    "average_electricity_charges.reset_index(inplace=True)\n",
    "average_electricity_charges\n",
    "\n",
    "#Check the cooking gasconsumption and cost locations dataset for null values, clean if needed. \n",
    "cookinggas_df.head\n",
    "\n",
    "#Grouping the data by 'Borough' and calculating the average of 'Current Charges' \n",
    "average_charges_cookinggas_df = cookinggas_df.groupby('Borough')[['Current Charges']].mean()\n",
    "\n",
    "#Reset the index to have 'Borough' as a column again\n",
    "average_charges_cookinggas_df.reset_index(inplace=True)\n",
    "\n",
    "average_charges_cookinggas_df\n",
    "\n",
    "\n",
    "#For average_charges_cookinggas_df and average_electricity_charges, they both can be combined\n",
    "##first rename the columns for clarity,\n",
    "average_charges_cookinggas_df = average_charges_cookinggas_df.rename(\n",
    "    columns={'Current Charges': 'Average_Cooking_Gas_Charges'}\n",
    ")\n",
    "average_electricity_charges = average_electricity_charges.rename(\n",
    "    columns={'Current Charges': 'Average_Electricity_Charges'}\n",
    ")\n",
    "\n",
    "#then merge the dataframes such that it shows the average utility costs for each borough\n",
    "average_utility_charges = pd.merge(\n",
    "    average_electricity_charges,\n",
    "    average_charges_cookinggas_df,\n",
    "    on='Borough',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Create a mask where only rows with 'Borough' not equal to 'NON DEVELOPMENT FACILITY' are True\n",
    "mask = average_utility_charges['Borough'] != 'NON DEVELOPMENT FACILITY'\n",
    "\n",
    "# Apply the mask to the DataFrame to filter out the unwanted rows\n",
    "average_utility_charges = average_utility_charges[mask]\n",
    "\n",
    "#print output\n",
    "average_utility_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>11436</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>11691</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>11692</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>11693</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>11694</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Zipcode  Frequency\n",
       "0      10001         65\n",
       "1      10002         24\n",
       "2      10003         82\n",
       "3      10004         51\n",
       "4      10005          9\n",
       "..       ...        ...\n",
       "167    11436          5\n",
       "168    11691         11\n",
       "169    11692          3\n",
       "170    11693         12\n",
       "171    11694         11\n",
       "\n",
       "[172 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the wifi hotspot locations dataset for null values, clean if needed. \n",
    "wifi_hotspot_df.columns\n",
    "\n",
    "#Renaming the 'Postcode' column to 'Zipcode'\n",
    "wifi_hotspot_df = wifi_hotspot_df.rename(columns={'Postcode': 'Zipcode'})\n",
    "\n",
    "# Group by 'Postcode' and count the frequency of WiFi hotspots\n",
    "wifi_frequency_by_zipcode = wifi_hotspot_df.groupby('Zipcode').size().reset_index(name='Frequency')\n",
    "wifi_frequency_by_zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zip \\nCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rivas Deli Grocery</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-Town</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La India Mini Market</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Hermanos</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Price Choice Food Market</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Piggy  Meat Corp</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Natural And Organic Deli Corp</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Keita West African Market Inc</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Organic Fresh Market Corps</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>City Star Deli Corp</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name   Borough  Zip \\nCode\n",
       "0               Rivas Deli Grocery     Bronx       10458\n",
       "1                           C-Town     Bronx       10460\n",
       "2             La India Mini Market     Bronx       10460\n",
       "3                     Los Hermanos     Bronx       10460\n",
       "4         Price Choice Food Market     Bronx       10460\n",
       "..                             ...       ...         ...\n",
       "670               Piggy  Meat Corp  Brooklyn       11221\n",
       "671  Natural And Organic Deli Corp  Brooklyn       11221\n",
       "672  Keita West African Market Inc  Brooklyn       11221\n",
       "673     Organic Fresh Market Corps  Brooklyn       11221\n",
       "674            City Star Deli Corp  Brooklyn       11221\n",
       "\n",
       "[675 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the grocery store locations dataset for null values, clean if needed. \n",
    "grocery_stores.columns\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop_stores = ['Street Address', 'Address', 'Year Awarded', 'Program \\nWave', 'Latitude', 'Longitude', 'Community Board', 'Council District', 'BIN', 'BBL','Census Tract (2020)', 'Neighborhood Tabulation Area (NTA) (2020)' ]\n",
    "grocery_stores.drop(columns=columns_to_drop_stores, inplace=True)\n",
    "grocery_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipcode\n",
      "10457    5\n",
      "11211    4\n",
      "11221    4\n",
      "11233    4\n",
      "10304    4\n",
      "        ..\n",
      "11232    1\n",
      "10463    1\n",
      "10471    1\n",
      "10464    1\n",
      "10309    1\n",
      "Name: count, Length: 145, dtype: int64\n",
      "FacilityName          0\n",
      "FacilityAddress       0\n",
      "Borough               0\n",
      "Zipcode               0\n",
      "Latitude              0\n",
      "Longitude             0\n",
      "Community Board       0\n",
      "Community Council     0\n",
      "Census Tract          0\n",
      "BIN                   0\n",
      "BBL                   0\n",
      "NTA                   0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                           FacilityName        Borough  Zipcode\n",
       "0                                   Engine 4/Ladder 15      Manhattan    10005\n",
       "1                                             Engine 6      Manhattan    10038\n",
       "2    Manhattan Borough Command/Battalion 1/Engine 7...      Manhattan    10007\n",
       "3                                             Ladder 8      Manhattan    10013\n",
       "4                                    Engine 9/Ladder 6      Manhattan    10002\n",
       "..                                                 ...            ...      ...\n",
       "214                               Engine 167/Ladder 87  Staten Island    10312\n",
       "215                               Engine 164/Ladder 84  Staten Island    10312\n",
       "216                               Engine 151/Ladder 76  Staten Island    10307\n",
       "217                                         Engine 168  Staten Island    10309\n",
       "218                                           Marine 9  Staten Island    10304\n",
       "\n",
       "[219 rows x 3 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the firehouse locations dataset for null values, clean if needed. \n",
    "firehouselocations_df\n",
    "\n",
    "# Renaming the 'Postcode' column to 'Zipcode'\n",
    "firehouselocations_df = firehouselocations_df.rename(columns={'Postcode': 'Zipcode'})\n",
    "\n",
    "#Counting the frequency of fire stations in each postcode\n",
    "fire_stations_per_zipcode = firehouselocations_df['Zipcode'].value_counts()\n",
    "print(fire_stations_per_zipcode)\n",
    "\n",
    "#View what all columns have null values \n",
    "null_values = firehouselocations_df.isnull().sum()\n",
    "print(null_values)\n",
    "\n",
    "firehouselocations_df = firehouselocations_df[['FacilityName', 'Borough', 'Zipcode']]\n",
    "firehouselocations_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upcoming projects in New York data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School Name</th>\n",
       "      <th>Project Description</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P.S. 95 - BRONX</td>\n",
       "      <td>DEFECTIVE MASONRY/PARAPETS</td>\n",
       "      <td>10463.0</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P.S. 19 - QUEENS</td>\n",
       "      <td>Addition</td>\n",
       "      <td>11368.0</td>\n",
       "      <td>QUEENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P.S. 138 - QUEENS</td>\n",
       "      <td>EXTERIOR MASONRY / FLOOD ELIMINATION / PARAPET...</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>QUEENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P.S. 37 - BRONX</td>\n",
       "      <td>PA SYSTEM REPLACEMENT</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P.S. 5 - STATEN ISLAND</td>\n",
       "      <td>Demo</td>\n",
       "      <td>10312.0</td>\n",
       "      <td>STATEN IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>THOMAS A. EDISON HS - Q</td>\n",
       "      <td>FY17 RESO A ROOM CONVERSIONS/PARTITIONING</td>\n",
       "      <td>11432.0</td>\n",
       "      <td>QUEENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13231</th>\n",
       "      <td>P.S. 214 - BRONX</td>\n",
       "      <td>ELECTRICAL WORK FOR A/C INITIATIVE / LL26 CODE...</td>\n",
       "      <td>10301.0</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13232</th>\n",
       "      <td>P.S. 150 - QUEENS</td>\n",
       "      <td>EXTERIOR MASONRY / FLOOD ELIMINATION / PARAPET...</td>\n",
       "      <td>10301.0</td>\n",
       "      <td>QUEENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13233</th>\n",
       "      <td>FORT HAMILTON HS - K</td>\n",
       "      <td>IP DIGITAL VIDEO SURVEILLANCE SYSTEM</td>\n",
       "      <td>11209.0</td>\n",
       "      <td>BROOKLYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13234</th>\n",
       "      <td>ADULT AND CONTINUING EDUCATION</td>\n",
       "      <td>EXTERIOR MASONRY / FLOOD ELIMINATION / LOW VOL...</td>\n",
       "      <td>10467.0</td>\n",
       "      <td>BROOKLYN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12430 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          School Name  \\\n",
       "3                     P.S. 95 - BRONX   \n",
       "4                    P.S. 19 - QUEENS   \n",
       "5                   P.S. 138 - QUEENS   \n",
       "6                     P.S. 37 - BRONX   \n",
       "7              P.S. 5 - STATEN ISLAND   \n",
       "...                               ...   \n",
       "13230         THOMAS A. EDISON HS - Q   \n",
       "13231                P.S. 214 - BRONX   \n",
       "13232               P.S. 150 - QUEENS   \n",
       "13233            FORT HAMILTON HS - K   \n",
       "13234  ADULT AND CONTINUING EDUCATION   \n",
       "\n",
       "                                     Project Description  Postcode    Borough  \n",
       "3                             DEFECTIVE MASONRY/PARAPETS   10463.0      BRONX  \n",
       "4                                               Addition   11368.0     QUEENS  \n",
       "5      EXTERIOR MASONRY / FLOOD ELIMINATION / PARAPET...   11204.0     QUEENS  \n",
       "6                                  PA SYSTEM REPLACEMENT   11204.0      BRONX  \n",
       "7                                                   Demo   10312.0  STATEN IS  \n",
       "...                                                  ...       ...        ...  \n",
       "13230          FY17 RESO A ROOM CONVERSIONS/PARTITIONING   11432.0     QUEENS  \n",
       "13231  ELECTRICAL WORK FOR A/C INITIATIVE / LL26 CODE...   10301.0      BRONX  \n",
       "13232  EXTERIOR MASONRY / FLOOD ELIMINATION / PARAPET...   10301.0     QUEENS  \n",
       "13233               IP DIGITAL VIDEO SURVEILLANCE SYSTEM   11209.0   BROOKLYN  \n",
       "13234  EXTERIOR MASONRY / FLOOD ELIMINATION / LOW VOL...   10467.0   BROOKLYN  \n",
       "\n",
       "[12430 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the active projects under construction for null values, clean if needed. \n",
    "projects_under_constr_df.columns\n",
    "\n",
    "#Dropping Columns that are not needed for visualization\n",
    "columns_to_drop_uc_projects = ['Geographical District', 'BoroughCode', 'Construction Award', 'Project type', 'Building ID', 'Building Address', 'City', 'Latitude', 'Longitude', 'Community Board', 'Council District', 'BIN', 'BBL', 'Census Tract (2020)', 'Neighborhood Tabulation Area (NTA) (2020)',  'Location 1' , 'Data As Of' ]\n",
    "projects_under_constr_df.drop(columns=columns_to_drop_uc_projects, inplace=True)\n",
    "\n",
    "#Drop rows with null values\n",
    "projects_under_constr_df = projects_under_constr_df.dropna()\n",
    "projects_under_constr_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to SQL Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Database Connection\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "database_url = \"postgresql://postgres:123@localhost:5432/nyc_projectmd\"\n",
    "engine = create_engine(database_url)\n",
    "# Establish a connection\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating all tables that were transformed in SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCmd = \"\"\"\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"Borough_masterdf\" (\n",
    "    \"borough_id\" INTEGER PRIMARY KEY,\n",
    "    \"borough\" VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS all_homes_by_bedrooms (\n",
    "    zipcode VARCHAR(10) NOT NULL,\n",
    "    bedrooms INT NOT NULL,\n",
    "    \"2024-02\" VARCHAR(150) NOT NULL,\n",
    "    \"2024-01\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-12\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-11\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-10\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-09\" VARCHAR(150) NOT NULL,\n",
    "    PRIMARY KEY (zipcode, bedrooms)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS all_homes_forecast (\n",
    "    zipcode VARCHAR(10) NOT NULL,\n",
    "    basedate DATE NOT NULL,\n",
    "    \"2024-03\" VARCHAR(150) NOT NULL,\n",
    "    \"2024-05\" VARCHAR(150) NOT NULL,\n",
    "    \"2025-02\" VARCHAR(150) NOT NULL,\n",
    "    PRIMARY KEY (zipcode)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS all_homes_observed_rent (\n",
    "    zipcode VARCHAR(10) NOT NULL,\n",
    "    \"2024-02\" VARCHAR(150) NOT NULL,\n",
    "    \"2024-01\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-12\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-11\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-10\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-09\" VARCHAR(150) NOT NULL,\n",
    "    PRIMARY KEY (zipcode)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS all_homes_final (\n",
    "    zipcode VARCHAR(10) NOT NULL,\n",
    "    \"2024-02\" VARCHAR(150) NOT NULL,\n",
    "    \"2024-01\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-12\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-11\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-10\" VARCHAR(150) NOT NULL,\n",
    "    \"2023-09\" VARCHAR(150) NOT NULL,\n",
    "    PRIMARY KEY (zipcode)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS final_crime_statistics (\n",
    "    zipcode VARCHAR(10),\n",
    "    average_crime_data FLOAT,\n",
    "    borough VARCHAR(150),\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS geography (\n",
    "    borough TEXT PRIMARY KEY,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS demographics (\n",
    "    borough TEXT PRIMARY KEY,\n",
    "    total_population INT,\n",
    "    men INT,\n",
    "    women INT,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough) REFERENCES geography (borough),\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS race_ethnicity (\n",
    "    borough TEXT PRIMARY KEY,\n",
    "    total_hispanic FLOAT,\n",
    "    total_white FLOAT,\n",
    "    total_black FLOAT,\n",
    "    total_native FLOAT,\n",
    "    total_asian FLOAT,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough) REFERENCES geography (borough),\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS economic_indicators (\n",
    "    borough TEXT PRIMARY KEY,\n",
    "    avg_income FLOAT,\n",
    "    total_employed INT,\n",
    "    total_unemployed INT,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough) REFERENCES geography (borough),\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS high_schools (\n",
    "    zip_code VARCHAR(150) NOT NULL,\n",
    "    borough VARCHAR(150) NOT NULL,\n",
    "    school_name VARCHAR(150) NOT NULL,\n",
    "    school_id SERIAL PRIMARY KEY,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS library (\n",
    "    library_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    zipcode VARCHAR(10) NOT NULL,\n",
    "    borough VARCHAR(150) NOT NULL,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS subway_stations (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    borough VARCHAR(150),\n",
    "    station_name VARCHAR(150) NOT NULL,\n",
    "    line VARCHAR(150),\n",
    "    ada_accessible BOOLEAN,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS nyc_borough_transportation (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    borough VARCHAR(150),\n",
    "    drive NUMERIC,\n",
    "    carpool NUMERIC,\n",
    "    transit NUMERIC,\n",
    "    walk NUMERIC,\n",
    "    other_transp NUMERIC,\n",
    "    work_at_home NUMERIC,\n",
    "    mean_commute NUMERIC,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS hospital_stage (\n",
    "    Facility_Type VARCHAR(150),\n",
    "    borough VARCHAR(50),\n",
    "    facility_name VARCHAR(150),\n",
    "    Cross_Streets TEXT,\n",
    "    Phone VARCHAR(18),\n",
    "    Location_1 TEXT,\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE nyc_parksdata (\n",
    "    acres FLOAT,\n",
    "    address VARCHAR(150),\n",
    "    borough VARCHAR(50),\n",
    "    class VARCHAR(50),\n",
    "    zipcode VARCHAR(50),\n",
    "    borough_id INTEGER,\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ");\n",
    "\n",
    "BEGIN;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"Latitude_Longitude_Zip\" (\n",
    "    \"zipcode\" VARCHAR(10) PRIMARY KEY,\n",
    "    \"latitude\" NUMERIC(10, 6),\n",
    "    \"longitude\" NUMERIC(10, 6)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"Borough_id_Zip\" (\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    \"borough_id\" INTEGER,\n",
    "    PRIMARY KEY (\"zipcode\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"restaurants\" (\n",
    "    \"restaurants_name\" VARCHAR(255),\n",
    "    \"rating\" NUMERIC(2, 1),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    PRIMARY KEY (\"restaurants_name\", \"zipcode\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"museums\" (\n",
    "    \"museum_name\" VARCHAR(255),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    PRIMARY KEY (\"museum_name\", \"zipcode\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"farmers_markets\" (\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"market_name\" VARCHAR(255),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    \"borough_id\" INTEGER,\n",
    "    PRIMARY KEY (\"market_name\", \"zipcode\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"swimming_pools\" (\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"swimming_pool_name\" VARCHAR(255),\n",
    "    \"borough_id\" INTEGER,\n",
    "    PRIMARY KEY (\"swimming_pool_name\", \"borough\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"theatres\" (\n",
    "    \"theatre_name\" VARCHAR(255),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    PRIMARY KEY (\"theatre_name\", \"zipcode\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"beaches\" (\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"beach_name\" VARCHAR(255),\n",
    "    \"borough_id\" INTEGER,\n",
    "    PRIMARY KEY (\"beach_name\", \"borough\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"athletic_facilities\" (\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"borough_id\" INTEGER,\n",
    "    \"ADULT_BASEBALL\" BOOLEAN,\n",
    "    \"ADULT_FOOTBALL\" BOOLEAN,\n",
    "    \"ADULT_SOFTBALL\" BOOLEAN,\n",
    "    \"BASKETBALL\" BOOLEAN,\n",
    "    \"BOCCE\" BOOLEAN,\n",
    "    \"CRICKET\" BOOLEAN,\n",
    "    \"FLAGFOOTBALL\" BOOLEAN,\n",
    "    \"FRISBEE\" BOOLEAN,\n",
    "    \"HANDBALL\" BOOLEAN,\n",
    "    \"HOCKEY\" BOOLEAN,\n",
    "    \"KICKBALL\" BOOLEAN,\n",
    "    \"LACROSSE\" BOOLEAN,\n",
    "    \"LL_BASEB_12ANDUNDER\" BOOLEAN,\n",
    "    \"LL_BASEB_13ANDOLDER\" BOOLEAN,\n",
    "    \"LL_SOFTBALL\" BOOLEAN,\n",
    "    \"NETBALL\" BOOLEAN,\n",
    "    \"NONREGULATION_SOCCER\" BOOLEAN,\n",
    "    \"REGULATION_SOCCER\" BOOLEAN,\n",
    "    \"RUGBY\" BOOLEAN,\n",
    "    \"TENNIS\" BOOLEAN,\n",
    "    \"T_BALL\" BOOLEAN,\n",
    "    \"VOLLEYBALL\" BOOLEAN,\n",
    "    \"WHEELCHAIRFOOTBALL\" BOOLEAN,\n",
    "    \"YOUTH_FOOTBALL\" BOOLEAN,\n",
    "    PRIMARY KEY (\"borough\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"average_utility_charges\" (\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"borough_id\" INTEGER,\n",
    "    \"average_electricity_charges\" NUMERIC(9, 2),\n",
    "    \"other_charges\" NUMERIC(9, 2),\n",
    "    \"average_cooking_gas_charges\" NUMERIC(9, 2),\n",
    "    PRIMARY KEY (\"borough\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"wifi_frequency\" (\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    \"Frequency\" INTEGER,\n",
    "    PRIMARY KEY (\"zipcode\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"grocery_stores\" (\n",
    "    \"store_name\" VARCHAR(255),\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    "    \"borough_id\" INTEGER,\n",
    "    PRIMARY KEY (\"store_name\", \"zipcode\"),\n",
    "    FOREIGN KEY (\"borough_id\") REFERENCES \"Borough_masterdf\" (\"borough_id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"fire_stations\" (\n",
    "    \"facility_name\" VARCHAR(255),\n",
    "    \"borough\" VARCHAR(100),\n",
    "    \"zipcode\" VARCHAR(10),\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"projects_under_construction\" (\n",
    "    \"school_name\" VARCHAR(255),\n",
    "    \"project_description\" TEXT,\n",
    "    \"postcode\" VARCHAR(10),\n",
    "    borough_id INTEGER,\n",
    "    \"borough\" VARCHAR(100),\n",
    "    PRIMARY KEY (\"school_name\", \"postcode\"),\n",
    "    FOREIGN KEY (borough_id) REFERENCES \"Borough_masterdf\" (borough_id)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING DATA TO POSTGRESQL DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the connection established, using the to_sql method to import all the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demographics\n",
    "boroughs_data.to_sql('geography', engine, if_exists='replace', index=False)\n",
    "demographics_agg.to_sql('demographics', engine, if_exists='replace', index=False)\n",
    "race_ethnicity_agg.to_sql('race_ethnicity', engine, if_exists='replace', index=False)\n",
    "economic_indicators_agg.to_sql('economic_indicators', engine, if_exists='replace', index=False)\n",
    "\n",
    "#Education and Transportation \n",
    "high_schools.to_sql('high_schools', engine, if_exists='replace', index=False)\n",
    "library_df.to_sql('library', engine, if_exists='replace', index=False)\n",
    "subway_df.to_sql('subway_stations', engine, if_exists='replace', index=False)\n",
    "borough_transportation.to_sql('nyc_borough_transportation', engine, if_exists='replace', index=False)\n",
    "borough_daily_avg.to_sql('borough_traffic_averages', engine, if_exists='replace', index=False)\n",
    "\n",
    "#Housing Data\n",
    "all_homes_by_bedrooms.to_sql('all_homes_by_bedrooms', engine, if_exists='replace', index=False)\n",
    "all_homes_final.to_sql('all_homes_final', engine, if_exists='replace', index=False)\n",
    "all_homes_forecast.to_sql('all_homes_forecast', engine, if_exists='replace', index=False)\n",
    "all_homes_observed_rent.to_sql('all_homes_observed_rent', engine, if_exists='replace', index=False)\n",
    "\n",
    "#Hospitals and Parks\n",
    "hospitals_df.to_sql('hospital_stage ', engine, if_exists='replace', index=False)\n",
    "final_parks.to_sql('nyc_parksdata', engine, if_exists='replace', index=False)\n",
    "\n",
    "#Entertainment\n",
    "restaurants_df.to_sql('restaurants', engine, if_exists='replace', index=False)\n",
    "museum_df.to_sql('museums', engine, if_exists='replace', index=False)\n",
    "markets_df.to_sql('farmers_markets', engine, if_exists='replace', index=False)\n",
    "swimmingpool_df.to_sql('swimming_pools', engine, if_exists='replace', index=False)\n",
    "theatres_df.to_sql('theatres', engine, if_exists='replace', index=False)\n",
    "unique_beaches_df.to_sql('beaches', engine, if_exists='replace', index=False)\n",
    "grouped_df_brgh.to_sql('athletic_facilities', engine, if_exists='replace', index=False)\n",
    "\n",
    "#Utilities\n",
    "average_utility_charges.to_sql('average_utility_charges', engine, if_exists='replace', index=False)\n",
    "wifi_frequency_by_zipcode.to_sql('wifi_frequency', engine, if_exists='replace', index=False)\n",
    "unique_beaches_df.to_sql('beaches', engine, if_exists='replace', index=False)\n",
    "grocery_stores.to_sql('grocery_stores', engine, if_exists='replace', index=False)\n",
    "firehouselocations_df.to_sql('fire_stations', engine, if_exists='replace', index=False)\n",
    "\n",
    "#Projects under construction\n",
    "projects_under_constr_df.to_sql('projects_under_construction', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL and ELT process Ends here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
